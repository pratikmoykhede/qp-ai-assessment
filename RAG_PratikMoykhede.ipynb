{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c251644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0614dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31532612",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea34267",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a94989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ba1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-base-en\"\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "model_norm = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e94b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faiss_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc330bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd91d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf503f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56805c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(texts, model_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d904d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99df401",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4eff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea857bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template1= \"\"\"You are an assistant for question-answering tasks. You will be given a question and context.\n",
    "Use the following context to answer the question.\n",
    "Follow the below guidelines:\n",
    "1.Understand the question and its meaning.\n",
    "2.Understand the semantic meaning of the context and what is it trying to convey.\n",
    "3.Based on the meanings of question and the context, if both the intents match, generate an answer to the question which is completely based on the context.\n",
    "4.If you are not able to find answer from the context , dont make up the answer ,say -'I dont know the answer to out-of-context question'.\n",
    "5.Give the detailed answer including all the important points from the context provided.\n",
    "  Context: {context}\n",
    "    Question: {question}\n",
    "    Answer :\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b969be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5648b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai==0.27.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8a4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70118c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa0bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever,return_source_documents=\"True\",chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b605af",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=qa(\"What is langchain?\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99892e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
